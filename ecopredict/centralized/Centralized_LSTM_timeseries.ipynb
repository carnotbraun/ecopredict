{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18e_wFgHA0Do"
      },
      "source": [
        "# Traffic forecasting using LSTM\n",
        "\n",
        "**Author:** Carnot Braun & Allan M.Sousa\n",
        "**Date created:** 2024/05/08<br>\n",
        "**Last modified:** 2024/05/08<br>\n",
        "**Description:** This example demonstrates how to do timeseries forecasting over graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl7IKZ2yA0Dr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas numpy matplotlib tensorflow keras scikit-learn seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GyJ2wd-8A0Dr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-17 15:36:23.756519: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-17 15:36:23.761737: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-07-17 15:36:23.802376: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-07-17 15:36:23.850270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-17 15:36:23.898494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-17 15:36:23.898762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-17 15:36:23.969115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-17 15:36:24.627824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import typing\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import time \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agregar as emissões por RSU, criando uma serie temporal para cada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xcAb6tI8tAjg"
      },
      "outputs": [],
      "source": [
        "def load_and_aggregate_data(folder_path):\n",
        "    all_data = []\n",
        "    \n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            road = os.path.splitext(filename)[0]\n",
        "            a = pd.read_csv(file_path, sep=',', header=None, usecols=[0, 1, 3], \n",
        "                            names=['step', 'road_id', 'c02_emission'], skiprows=[0])\n",
        "            \n",
        "            # Converte o tempo para datetime\n",
        "            a['step'] = pd.to_datetime(a['step'], unit='s')\n",
        "            \n",
        "            # Converte c02_emission para numérico, forçando erros a NaN e preenchendo NaN com 0\n",
        "            a['c02_emission'] = pd.to_numeric(a['c02_emission'], errors='coerce').fillna(0)\n",
        "            \n",
        "            # Agrupa por 1 segundo, somando apenas colunas numéricas\n",
        "            a = a.groupby([pd.Grouper(key='step', freq='1s')])[['c02_emission']].sum().reset_index()\n",
        "            a['road_id'] = road\n",
        "            \n",
        "            all_data.append(a)\n",
        "    \n",
        "    # Combina todos os dados de diferentes RSUs em um único DataFrame\n",
        "    aggregated_data = pd.concat(all_data, axis=0).reset_index(drop=True)\n",
        "    \n",
        "    return aggregated_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_time_series(data, time_col, value_col):\n",
        "    data = data.sort_values(by=time_col)\n",
        "    data[value_col] = data[value_col].rolling(5).mean()\n",
        "    data.dropna(inplace=True)\n",
        "    time_series = data[[time_col, value_col]].set_index(time_col)\n",
        "    return time_series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparar os dados do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_lstm_data(series, n_steps):\n",
        "    X, y = [], []\n",
        "    horizon = 15\n",
        "    series = pd.Series(series).rolling(60).mean()\n",
        "    series.dropna(inplace=True)\n",
        "    series = series.values\n",
        "    \n",
        "    for i in range(len(series)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix + horizon > len(series)-1:\n",
        "            break\n",
        "        seq_x, seq_y = series[i:end_ix], series[end_ix + horizon]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape))\n",
        "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "folder_path = '/home/carnot/hiaac/data/rsus_cologne_csv/rsus/'  # Altere para o caminho correto\n",
        "rsu_data = load_and_aggregate_data(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Treinamento da LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_steps = 10\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for rsu, group in rsu_data.groupby('road_id'):\n",
        "    time_series = create_time_series(group, 'step', 'c02_emission')\n",
        "    series = scaler.fit_transform(time_series.values).flatten()\n",
        "    X, y = prepare_lstm_data(series, n_steps)\n",
        "    \n",
        "    split_index = int(len(X) * 0.65)  # 65% para treino\n",
        "    X_train, X_test = X[:split_index], X[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "    \n",
        "    train_data.append((X_train, y_train))\n",
        "    test_data.append((X_test, y_test))\n",
        "\n",
        "X_train_agg = np.concatenate([data[0] for data in train_data], axis=0)\n",
        "y_train_agg = np.concatenate([data[1] for data in train_data], axis=0)\n",
        "X_test_agg = np.concatenate([data[0] for data in test_data], axis=0)\n",
        "y_test_agg = np.concatenate([data[1] for data in test_data], axis=0)\n",
        "\n",
        "X_train_agg = X_train_agg.reshape((X_train_agg.shape[0], X_train_agg.shape[1], 1))\n",
        "X_test_agg = X_test_agg.reshape((X_test_agg.shape[0], X_test_agg.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2024-07-17 15:37:13.763271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-17 15:37:13.763573: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 3.354700312293626e-05\n",
            "Execution Time: 4851.958208575 seconds\n"
          ]
        }
      ],
      "source": [
        "model = create_lstm_model((X_train_agg.shape[1], 1))\n",
        "\n",
        "start_time = time.process_time()\n",
        "model.fit(X_train_agg, y_train_agg, epochs=50, verbose=0)\n",
        "end_time = time.process_time()\n",
        "\n",
        "# Avaliar o modelo\n",
        "y_pred = model.predict(X_test_agg, verbose=0)\n",
        "mse = np.mean((y_test_agg - y_pred.flatten())**2)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Execution Time: {end_time - start_time} seconds\")\n",
        "\n",
        "# Salvar tempos de execução e erros\n",
        "times = pd.DataFrame([(n_steps, end_time - start_time)], columns=['steps', 'time'])\n",
        "times.to_csv('time_h15.csv', index=False)\n",
        "\n",
        "errors = pd.DataFrame([(n_steps, mse)], columns=['steps', 'MSE'])\n",
        "errors.to_csv('lstm_errors_h15.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_weights('model_h15.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights('model_h30.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load weights/compare with RSUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6107/987271170.py:8: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  a = pd.read_csv(file_path, sep=',', header=None, usecols=[0, 1, 3],\n",
            "/tmp/ipykernel_6107/987271170.py:8: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  a = pd.read_csv(file_path, sep=',', header=None, usecols=[0, 1, 3],\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_0, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_1, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_2, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_3, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_4, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/home/carnot/hiaac/learning_framework/frameworks/ecopredict/centralized/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RSU: RSU_5, Mean Squared Error: 7.270263999401529e-08\n"
          ]
        }
      ],
      "source": [
        "# Carregar os pesos treinados\n",
        "weights_file = '/home/carnot/Downloads/model_h30.weights.h5'\n",
        "\n",
        "# Caminho para a pasta com os dados das RSUs\n",
        "folder_path = '/home/carnot/hiaac/data/most/rsus_most_csv/' \n",
        "\n",
        "# Carregar os dados das RSUs\n",
        "rsu_data = load_and_aggregate_data(folder_path)\n",
        "\n",
        "n_steps = 10\n",
        "scaler = MinMaxScaler()\n",
        "results = []\n",
        "\n",
        "for rsu, group in rsu_data.groupby('road_id'):\n",
        "    time_series = create_time_series(group, 'step', 'c02_emission')\n",
        "    series = scaler.fit_transform(time_series.values).flatten()\n",
        "    X, y = prepare_lstm_data(series, n_steps)\n",
        "    \n",
        "    split_index = int(len(X) * 0.65)  # 65% para treino\n",
        "    X_train, X_test = X[:split_index], X[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "    \n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Criar e carregar os pesos no modelo\n",
        "    model = create_lstm_model((X_test.shape[1], 1))\n",
        "    model.load_weights(weights_file)\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    mse = np.mean((y_test - y_pred.flatten())**2)\n",
        "    \n",
        "    results.append({'RSU': rsu, 'MSE': mse})\n",
        "    print(f\"RSU: {rsu}, Mean Squared Error: {mse}\")\n",
        "\n",
        "    # Salvar os resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('lstm_errors_h30.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
